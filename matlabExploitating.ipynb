{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import the necessary libraries, including scipy.io for reading MATLAB files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required library\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the constants for the Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_DURATION = 64\n",
    "INTENSIFIED_N_TIMES = 20\n",
    "N_CHARACTERS = 36"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Function to Load MATLAB Files\n",
    "Define a function that uses scipy.io.loadmat() to load a MATLAB file and return the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_matlab_file(file_path):\n",
    "    data = sio.loadmat(file_path)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the MATLAB Files\n",
    "Use the defined function to load data from a series of MATLAB files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(347704, 8)\n",
      "(347704, 8)\n",
      "(347704, 8)\n",
      "(347704, 8)\n",
      "(347704, 8)\n",
      "(347704, 8)\n",
      "(347704, 8)\n",
      "(347704, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(134400, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of MATLAB files\n",
    "matlab_files = os.listdir('data/raw')\n",
    "\n",
    "# Initialize an empty dictionary to store the data from all files\n",
    "all_data = {}\n",
    "\n",
    "# Loop through each file\n",
    "for file in matlab_files:\n",
    "    # Load the data from the file using the function defined above\n",
    "    raw_data = load_matlab_file(f\"data/raw/{file}\")['data'][0]\n",
    "    eeg_data = raw_data['X'][0] # Shape  (347704, 8)\n",
    "    print(eeg_data.shape)\n",
    "    stimulus_type = raw_data['y'][0]  # Shape (347704, 1)\n",
    "    stimulus_class = raw_data['y_stim'][0] # Shape (347704, 1)\n",
    "    # trial_start_indices = data['trial'][0][0] # Shape (35, 1)\n",
    "    \n",
    "    # Create a DataFrame with eeg_data, stimulus_type, and stimulus_class\n",
    "    data = pd.DataFrame(eeg_data, columns=[f'ch_{i}' for i in range(1, 9)])\n",
    "    data['stimulus_type'] = stimulus_type\n",
    "    data['stimulus_class'] = stimulus_class\n",
    "\n",
    "    # Now we filter the data to only include the rows where the stimulus_type is 1 or 2\n",
    "    data = data[data['stimulus_type'].isin([1, 2])]\n",
    "\n",
    "    # Store the data in the dictionary\n",
    "    all_data[file] = data\n",
    "\n",
    "all_data['A01.mat'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conver the matlab matrices to numpy arrays\n",
    "\n",
    "And then create a DataFrame with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(filename, data):\n",
    "    np.save(filename, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Trial info:\n",
    "(64 x 20 = 1280) samples per trial\n",
    "(samples_per_stimuli x n_stimuli x n_characters)\n",
    "\"\"\"\n",
    "def transform_data(data: list, subject: int, n_samples, sample_offset: int = 32):\n",
    "    eeg_data = data['X'][0]\n",
    "    stimulus_type = data['y'][0]\n",
    "    trial_start_indices = data['trial'][0][0]\n",
    "\n",
    "    trial_duration = SAMPLE_DURATION * INTENSIFIED_N_TIMES\n",
    "\n",
    "    sample_duration_to_use = int(SAMPLE_DURATION * n_samples)\n",
    "\n",
    "    final_data = np.zeros((2, # 2 classes\n",
    "                           sample_duration_to_use,  # number of samples to take into account per trial\n",
    "                           INTENSIFIED_N_TIMES * len(trial_start_indices),  # number of trials\n",
    "                           8)) # number of channels\n",
    "\n",
    "    # (#n_trial, #channels, #time, #depth)\n",
    "    for i, start_idx in enumerate(trial_start_indices):\n",
    "        end_idx = start_idx + trial_duration\n",
    "        trial_data = eeg_data[(start_idx + sample_offset):(end_idx + sample_offset)]\n",
    "        trial_stimulus_type = stimulus_type[(start_idx + sample_offset):(end_idx + sample_offset)]\n",
    "\n",
    "        # Reshape the trial data to have the shape (64,   20,                , 8)\n",
    "        trial_data_ = trial_data.reshape((sample_duration_to_use, int(INTENSIFIED_N_TIMES / n_samples), 8))\n",
    "        trial_stimulus_type_ = trial_stimulus_type.reshape((sample_duration_to_use, int(INTENSIFIED_N_TIMES / n_samples), 1))\n",
    "\n",
    "        # Loop through each observation in the trial\n",
    "        for j in range(INTENSIFIED_N_TIMES):\n",
    "            # Get the stimulus type\n",
    "            stimulus_type_ = trial_stimulus_type_[:, j]\n",
    "\n",
    "            # Get the data for the character\n",
    "            character_data = trial_data_[:, j, :]\n",
    "\n",
    "            # Check if the stimulus type is 1 (not target) or 2 (target)\n",
    "            if 1 in stimulus_type_:\n",
    "                # Append the data to the final_data array\n",
    "                final_data[0, :, i * INTENSIFIED_N_TIMES + j] = character_data\n",
    "            else:\n",
    "                # Append the data to the final_data array\n",
    "                final_data[1, :, i * INTENSIFIED_N_TIMES + j] = character_data\n",
    "\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: A01.mat\n",
      "File: A02.mat\n",
      "File: A03.mat\n",
      "File: A04.mat\n",
      "File: A05.mat\n",
      "File: A06.mat\n",
      "File: A07.mat\n",
      "File: A08.mat\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Data set\n",
    "X=[samples X Channels]\n",
    "Y=[StimType X 1] ( 1 = NonTarget stimulus, 2 = Target Stimulus)\n",
    "Y_stim= [StimClass X 1] intensified stimulus classes (Figure 2)\n",
    "Trial=[Trials X 1] trial start in samples\n",
    "Classes = textual description of conditions related to Y\n",
    "Classes_stim = textual description of conditions related to Y_stim\n",
    "\"\"\"\n",
    "files = [\"A01.mat\",\"A02.mat\",\"A03.mat\",\"A04.mat\",\"A05.mat\",\"A06.mat\",\"A07.mat\",\"A08.mat\"]\n",
    "\n",
    "\n",
    "# Create directories for classes 0 and 1\n",
    "os.makedirs('./data/partitioned/class_1', exist_ok=True)\n",
    "os.makedirs('./data/partitioned/class_2', exist_ok=True)\n",
    "\n",
    "for file in files:\n",
    "    matlab_data = load_matlab_file(f\"data/raw/{file}\")['data'][0]\n",
    "    df = transform_data(matlab_data, file.replace('.mat', ''), 0.5)\n",
    "    print(f\"File: {file}\") # (2, 32, 700, 8) 700 is because 35 * 20 (35 chars * 20 intensitifacted per char)\n",
    "\n",
    "\n",
    "    # Now, save the data to the respective directories\n",
    "    save_data(f'./data/partitioned/class_1/{file.replace(\".mat\", \"\")}', df[0])\n",
    "    save_data(f'./data/partitioned/class_2/{file.replace(\".mat\", \"\")}', df[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1,2,3]])\n",
    "print(x.shape)\n",
    "np.swapaxes(x,0,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "min2net",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
