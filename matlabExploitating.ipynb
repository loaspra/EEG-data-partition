{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import the necessary libraries, including scipy.io for reading MATLAB files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required library\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Function to Load MATLAB Files\n",
    "Define a function that uses scipy.io.loadmat() to load a MATLAB file and return the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_matlab_file(file_path):\n",
    "    data = sio.loadmat(file_path)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the MATLAB Files\n",
    "Use the defined function to load data from a series of MATLAB files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of MATLAB files\n",
    "matlab_files = os.listdir('data/raw')\n",
    "\n",
    "# Initialize an empty dictionary to store the data from all files\n",
    "all_data = {}\n",
    "\n",
    "# Loop through each file\n",
    "for file in matlab_files:\n",
    "    # Load the data from the file using the function defined above\n",
    "    data = load_matlab_file(f\"data/raw/{file}\")['data'][0]\n",
    "    \n",
    "    # Add the data to the all_data dictionary\n",
    "    # The key is the file name and the value is the data\n",
    "    all_data[file] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conver the matlab matrices to numpy arrays\n",
    "\n",
    "And then create a DataFrame with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(filename, data):\n",
    "    np.save(filename, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(data: list, subject: int):\n",
    "    eeg_data = data['X'][0]\n",
    "    print(\"Second: \", eeg_data.shape)\n",
    "    stimulus_type = data['y'][0]\n",
    "    stimulus_class = data['y_stim'][0]\n",
    "    trial_start_indices = data['trial'][0][0]\n",
    "    print('dataTrial', len(trial_start_indices))\n",
    "\n",
    "    trial_duration = 1280\n",
    "\n",
    "    final_data = np.zeros((2, len(trial_start_indices), 8, trial_duration, 1))\n",
    "    print(eeg_data.shape)\n",
    "\n",
    "    # (#n_trial, #channels, #time, #depth)\n",
    "    for i, start_idx in enumerate(trial_start_indices):\n",
    "        end_idx = start_idx + trial_duration\n",
    "        trial_data = eeg_data[start_idx:end_idx]\n",
    "        trial_stimulus_type = stimulus_type[start_idx:end_idx]\n",
    "        trial_stimulus_class = stimulus_class[start_idx:end_idx]\n",
    "\n",
    "        # Determine the folder based on the stimulus type\n",
    "        # Cuando es class_1 es NO p300, cuando es class_2 es P300\n",
    "        clase = 1 if trial_stimulus_type[0] == 1 else 2\n",
    "        final_data[clase - 1, i, :, :trial_data.shape[0], 0] = trial_data.swapaxes(0, 1)\n",
    "\n",
    "    print(\"Final: \", final_data[0].shape)\n",
    "    print(\"Final: \", final_data[1].shape)\n",
    "        \n",
    "    # Save the data\n",
    "    save_data(os.path.join(\"./data/partitioned/\", 'class_1', f'{subject}_data.npy'), final_data[0])\n",
    "    save_data(os.path.join(\"./data/partitioned/\", 'class_2', f'{subject}_data.npy'), final_data[1])\n",
    "\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second:  (347704, 8)\n",
      "dataTrial 35\n",
      "(347704, 8)\n",
      "Final:  (35, 8, 1280, 1)\n",
      "Final:  (35, 8, 1280, 1)\n",
      "Second:  (347704, 8)\n",
      "dataTrial 35\n",
      "(347704, 8)\n",
      "Final:  (35, 8, 1280, 1)\n",
      "Final:  (35, 8, 1280, 1)\n",
      "Second:  (347704, 8)\n",
      "dataTrial 35\n",
      "(347704, 8)\n",
      "Final:  (35, 8, 1280, 1)\n",
      "Final:  (35, 8, 1280, 1)\n",
      "Second:  (347704, 8)\n",
      "dataTrial 35\n",
      "(347704, 8)\n",
      "Final:  (35, 8, 1280, 1)\n",
      "Final:  (35, 8, 1280, 1)\n",
      "Second:  (347704, 8)\n",
      "dataTrial 35\n",
      "(347704, 8)\n",
      "Final:  (35, 8, 1280, 1)\n",
      "Final:  (35, 8, 1280, 1)\n",
      "Second:  (347704, 8)\n",
      "dataTrial 35\n",
      "(347704, 8)\n",
      "Final:  (35, 8, 1280, 1)\n",
      "Final:  (35, 8, 1280, 1)\n",
      "Second:  (347704, 8)\n",
      "dataTrial 35\n",
      "(347704, 8)\n",
      "Final:  (35, 8, 1280, 1)\n",
      "Final:  (35, 8, 1280, 1)\n",
      "Second:  (347704, 8)\n",
      "dataTrial 35\n",
      "(347704, 8)\n",
      "Final:  (35, 8, 1280, 1)\n",
      "Final:  (35, 8, 1280, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Data set\n",
    "X=[samples X Channels]\n",
    "Y=[StimType X 1] ( 1 = NonTarget stimulus, 2 = Target Stimulus)\n",
    "Y_stim= [StimClass X 1] intensified stimulus classes (Figure 2)\n",
    "Trial=[Trials X 1] trial start in samples\n",
    "Classes = textual description of conditions related to Y\n",
    "Classes_stim = textual description of conditions related to Y_stim\n",
    "\"\"\"\n",
    "files = [\"A01.mat\",\"A02.mat\",\"A03.mat\",\"A04.mat\",\"A05.mat\",\"A06.mat\",\"A07.mat\",\"A08.mat\"]\n",
    "\n",
    "\n",
    "# Create directories for classes 0 and 1\n",
    "os.makedirs('./data/partitioned/class_1', exist_ok=True)\n",
    "os.makedirs('./data/partitioned/class_2', exist_ok=True)\n",
    "\n",
    "for file in files:\n",
    "    transform_data(load_matlab_file(f\"data/raw/{file}\")['data'][0], file.replace('.mat', ''))\n",
    "\n",
    "# Auxiliary variables\n",
    "classes = all_data['A01.mat'][0]['classes']\n",
    "classes_stim = all_data['A01.mat'][0]['classes_stim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1,2,3]])\n",
    "print(x.shape)\n",
    "np.swapaxes(x,0,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "min2net",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
